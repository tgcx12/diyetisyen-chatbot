import os
import requests
import gradio as gr
import webbrowser
from typing import List, Tuple

# =========================
# CONFIG
# =========================
OLLAMA_URL = os.environ.get("OLLAMA_URL", "http://localhost:11434")
MODEL_NAME = os.environ.get("OLLAMA_MODEL", "llama3.1:8b")

DEFAULT_TEMPERATURE = float(os.environ.get("TEMPERATURE", "0.2"))
DEFAULT_MAX_TOKENS = int(os.environ.get("MAX_TOKENS", "700"))

HOST = os.environ.get("GRADIO_HOST", "127.0.0.1")  # <- Ã–NEMLÄ°: 0.0.0.0 deÄŸil
PORT = int(os.environ.get("GRADIO_PORT", "7860"))

# =========================
# SYSTEM PROMPT
# =========================
SYSTEM_PROMPT = """Sen deneyimli bir diyetisyen asistanÄ±sÄ±n.
KullanÄ±cÄ±ya TÃ¼rkÃ§e, anlaÅŸÄ±lÄ±r, pratik ve gÃ¼venli Ã¶neriler ver.
Ã–nceliklerin:
1) GÃ¼venlik: Tehlikeli/uygunsuz Ã¶neri verme.
2) KiÅŸiselleÅŸtirme: YaÅŸ, boy, kilo, cinsiyet, aktivite, hedef, hastalÄ±klar, ilaÃ§lar, alerjiler, hamilelik/emzirme gibi bilgileri gerekirse nazikÃ§e sor.
3) Netlik: Maddeler halinde, Ã¶lÃ§Ã¼lÃ¼ porsiyon Ã¶nerileriyle, uygulanabilir plan sun.

TÄ±bbi hassasiyet kurallarÄ±:
- KullanÄ±cÄ± ciddi semptomlar (gÃ¶ÄŸÃ¼s aÄŸrÄ±sÄ±, bayÄ±lma, nefes darlÄ±ÄŸÄ±, kanlÄ± kusma/dÄ±ÅŸkÄ±, ÅŸiddetli dehidratasyon, bilinÃ§ deÄŸiÅŸikliÄŸi vb.) bildirirse acile baÅŸvurmasÄ±nÄ± Ã¶ner.
- Diyabet, bÃ¶brek yetmezliÄŸi, karaciÄŸer hastalÄ±ÄŸÄ±, gut, yeme bozukluÄŸu Ã¶ykÃ¼sÃ¼, hamilelik/emzirme, 18 yaÅŸ altÄ± gibi durumlarda â€œgenel bilgiâ€ ver; tedavi/ilaÃ§ dozuna girme; doktora/diyetisyene yÃ¶nlendir.
- AÅŸÄ±rÄ± kÄ±sÄ±tlayÄ±cÄ±, Ã§ok dÃ¼ÅŸÃ¼k kalorili, hÄ±zlÄ± kilo verdiren, â€œdetoksâ€ gibi iddialÄ± ve kanÄ±tsÄ±z Ã¶nerilerden kaÃ§Ä±n.
- Kalori/makro hesabÄ± istenirse kabaca tahmini aralÄ±klar ver ve bunun klinik deÄŸerlendirme olmadÄ±ÄŸÄ±nÄ± belirt.

YanÄ±t biÃ§imi:
- KÄ±sa bir Ã¶zet + ardÄ±ndan maddeli Ã¶neriler.
- Gerekirse 3-5 kÄ±sa soru sorarak bilgileri tamamla.
- KullanÄ±cÄ± â€œplanâ€ isterse: 1 gÃ¼nlÃ¼k Ã¶rnek menÃ¼ + alternatifler + alÄ±ÅŸveriÅŸ/uygulama ipuÃ§larÄ± ver.
"""

# =========================
# OLLAMA CHAT STREAM
# =========================
def ollama_chat_stream(messages: List[dict], temperature: float, num_predict: int):
    url = f"{OLLAMA_URL}/api/chat"
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "options": {
            "temperature": float(temperature),
            "num_predict": int(num_predict),
        },
        "stream": True,
    }

    try:
        with requests.post(url, json=payload, stream=True, timeout=300) as r:
            r.raise_for_status()
            full_text = ""
            for line in r.iter_lines(decode_unicode=True):
                if not line:
                    continue
                try:
                    obj = requests.utils.json.loads(line)
                except Exception:
                    continue
                if obj.get("done"):
                    break
                chunk = obj.get("message", {}).get("content", "")
                if chunk:
                    full_text += chunk
                    yield full_text
    except requests.exceptions.ConnectionError:
        yield "âŒ Ollama'ya baÄŸlanamadÄ±m. Ollama aÃ§Ä±k mÄ±? (VarsayÄ±lan: http://localhost:11434)"
    except requests.exceptions.HTTPError as e:
        yield f"âŒ Ollama HTTP hatasÄ±: {e}"
    except Exception as e:
        yield f"âŒ Beklenmeyen hata: {e}"

# =========================
# CHAT LOGIC
# =========================
def build_messages_from_history(history: List[Tuple[str, str]], user_message: str) -> List[dict]:
    msgs = [{"role": "system", "content": SYSTEM_PROMPT}]
    for u, a in history:
        if u:
            msgs.append({"role": "user", "content": u})
        if a:
            msgs.append({"role": "assistant", "content": a})
    msgs.append({"role": "user", "content": user_message})
    return msgs

def respond(user_message: str, history: List[Tuple[str, str]], temperature: float, max_tokens: int):
    user_message = (user_message or "").strip()
    if not user_message:
        yield history
        return

    messages = build_messages_from_history(history, user_message)
    history = history + [(user_message, "")]

    for partial in ollama_chat_stream(messages, temperature, max_tokens):
        history[-1] = (user_message, partial)
        yield history

def reset_chat():
    return []

# =========================
# UI
# =========================
CSS = """
:root{
  --bg:#0b1220;
  --card:#0f1a30;
  --muted:#91a4c7;
  --accent:#4fd1c5;
}
body{background:var(--bg)!important;}
.gradio-container{max-width: 980px !important;}
#title h1{letter-spacing:0.2px}
#subtitle{color:var(--muted); margin-top:-6px}
#card{
  background:linear-gradient(180deg, rgba(79,209,197,0.12), rgba(79,209,197,0.02));
  border:1px solid rgba(79,209,197,0.25);
  border-radius:18px;
  padding:14px 16px;
}
"""

DESCRIPTION = """
<div id="card">
<b>ğŸ¥— Diyet AsistanÄ± (LLaMA 3.1:8B)</b><br/>
<span style="color:#91a4c7">
Sorunu yaz; sana gÃ¼venli, uygulanabilir beslenme Ã¶nerileriyle yanÄ±t vereyim.
Ä°stersen hedefini (kilo verme/kilo alma/performans), yaÅŸ-boy-kilo ve varsa hastalÄ±k/ilaÃ§ bilgini de ekle.
</span>
</div>
"""

EXAMPLES = [
    "Kilo vermek istiyorum. 28 yaÅŸ, 168 cm, 78 kg. Ofis iÅŸiyim. Nereden baÅŸlamalÄ±yÄ±m?",
    "Ä°nsÃ¼lin direncim var. KahvaltÄ±da ne yemeliyim? Pratik Ã¶neri verir misin?",
    "Spora yeni baÅŸladÄ±m. Kas yapmak iÃ§in gÃ¼nlÃ¼k beslenmem nasÄ±l olmalÄ±?",
    "AkÅŸam Ã§ok acÄ±kÄ±yorum, gece atÄ±ÅŸtÄ±rmalarÄ±nÄ± nasÄ±l bÄ±rakÄ±rÄ±m?",
]

with gr.Blocks() as demo:
    gr.Markdown("<div id='title'><h1>ğŸ¥— Diyetisyen Chat</h1></div>")
    gr.Markdown("<div id='subtitle'>LLaMA 3.1:8B ile sohbet â€” doÄŸal dilde beslenme danÄ±ÅŸmanÄ±</div>")
    gr.Markdown(DESCRIPTION)

    with gr.Row():
        temperature = gr.Slider(0.0, 1.0, value=DEFAULT_TEMPERATURE, step=0.05, label="Temperature (yaratÄ±cÄ±lÄ±k)")
        max_tokens = gr.Slider(128, 1500, value=DEFAULT_MAX_TOKENS, step=32, label="Max tokens (cevap uzunluÄŸu)")

    chat = gr.Chatbot(label="Sohbet", height=520)

    with gr.Row():
        msg = gr.Textbox(label="Sorunu yaz", placeholder="Ã–rn: 1 haftalÄ±k pratik kilo verme planÄ± yapar mÄ±sÄ±n?", scale=10)
        send = gr.Button("GÃ¶nder", variant="primary", scale=2)

    with gr.Row():
        clear = gr.Button("Sohbeti SÄ±fÄ±rla")
        gr.Markdown("<span style='color:#91a4c7'>Not: Bu bir tÄ±bbi teÅŸhis aracÄ± deÄŸildir. Acil durumda 112/ACÄ°L.</span>")

    gr.Examples(EXAMPLES, inputs=msg)

    state = gr.State([])

    def on_send(user_message, history, t, mt):
        return respond(user_message, history, t, mt)

    send.click(on_send, inputs=[msg, state, temperature, max_tokens], outputs=[chat], queue=True)
    msg.submit(on_send, inputs=[msg, state, temperature, max_tokens], outputs=[chat], queue=True)

    chat.change(lambda h: h, inputs=[chat], outputs=[state], queue=False)

    send.click(lambda: "", outputs=[msg], queue=False)
    msg.submit(lambda: "", outputs=[msg], queue=False)

    clear.click(reset_chat, outputs=[chat], queue=False)
    clear.click(reset_chat, outputs=[state], queue=False)

if __name__ == "__main__":
    url = f"http://{HOST}:{PORT}"
    print("\n" + "=" * 60)
    print("âœ… Diyetisyen Chat calisiyor!")
    print(f"ğŸ‘‰ Tarayicida ac: {url}")
    print("=" * 60 + "\n")

    # TarayÄ±cÄ±yÄ± otomatik aÃ§ (Windowsâ€™ta Ã§alÄ±ÅŸÄ±r)
    try:
        webbrowser.open(url)
    except Exception:
        pass

    demo.queue(default_concurrency_limit=8).launch(
        server_name=HOST,
        server_port=PORT,
        theme=gr.themes.Soft(),
        css=CSS,
        prevent_thread_lock=False,  # terminal aÃ§Ä±k kalsÄ±n
    )
